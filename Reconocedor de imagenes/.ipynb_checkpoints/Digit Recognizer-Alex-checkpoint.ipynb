{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Como podemos observar tenemos 10 etiquetas** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaramos variables para entrenar nuestro modelo\n",
    "\n",
    "Como podemos observar la columna `label` van a ser nuestras respuestas que vamos a almacenar en la variable `y` y nuestra variable `X` van a ser todas las demas columnas excepto la primera ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"label\",axis=1).values\n",
    "y = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Si deseamos ver la imagen vectorizada simplemente llamamos la imagen que deseemos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  18,  30, 137, 137, 192,  86,  72,   1,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  13,  86, 250, 254, 254, 254, 254, 217,\n",
       "       246, 151,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  16, 179, 254, 254, 254, 254, 254,\n",
       "       254, 254, 254, 254, 231,  54,  15,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  72, 254, 254, 254, 254,\n",
       "       254, 254, 254, 254, 254, 254, 254, 254, 104,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 191, 254, 254,\n",
       "       254, 254, 254, 109,  83, 199, 254, 254, 254, 254, 243,  85,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 172, 254,\n",
       "       254, 254, 202, 147, 147,  45,   0,  11,  29, 200, 254, 254, 254,\n",
       "       171,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "       174, 254, 254,  89,  67,   0,   0,   0,   0,   0,   0, 128, 252,\n",
       "       254, 254, 212,  76,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  47, 254, 254, 254,  29,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  83, 254, 254, 254, 153,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  80, 254, 254, 240,  24,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  25, 240, 254, 254, 153,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  64, 254, 254, 186,   7,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0, 166, 254, 254, 224,  12,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  14, 232, 254, 254, 254,  29,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  75, 254, 254, 254,  17,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  18, 254, 254, 254, 254,\n",
       "        29,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 254, 254,\n",
       "       254,  17,   0,   0,   0,   0,   0,   0,   0,   0,   2, 163, 254,\n",
       "       254, 254,  29,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48,\n",
       "       254, 254, 254,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        94, 254, 254, 254, 200,  12,   0,   0,   0,   0,   0,   0,   0,\n",
       "        16, 209, 254, 254, 150,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  15, 206, 254, 254, 254, 202,  66,   0,   0,   0,   0,\n",
       "         0,  21, 161, 254, 254, 245,  31,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  60, 212, 254, 254, 254, 194,  48,  48,\n",
       "        34,  41,  48, 209, 254, 254, 254, 171,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  86, 243, 254, 254, 254,\n",
       "       254, 254, 233, 243, 254, 254, 254, 254, 254,  86,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 114, 254,\n",
       "       254, 254, 254, 254, 254, 254, 254, 254, 254, 239,  86,  11,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        13, 182, 254, 254, 254, 254, 254, 254, 254, 254, 243,  70,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   8,  76, 146, 254, 255, 254, 255, 146,  19,  15,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1] # De esta manera se ve una imgen vectorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd74d7b8828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[9].reshape(28,28)) # Para mostrar nuestra imagen aplicamos \"imshow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd74d744b00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[9].reshape(28,28),cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos nuestra data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la instancia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPC = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=700, alpha=2e-8,\n",
    "                     solver='sgd', verbose=10,  random_state=101,tol=0.00001,n_iter_no_change = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.69600500\n",
      "Iteration 2, loss = 0.44985221\n",
      "Iteration 3, loss = 0.36339507\n",
      "Iteration 4, loss = 0.31998652\n",
      "Iteration 5, loss = 0.28751296\n",
      "Iteration 6, loss = 0.26113305\n",
      "Iteration 7, loss = 0.24281855\n",
      "Iteration 8, loss = 0.22592921\n",
      "Iteration 9, loss = 0.21356832\n",
      "Iteration 10, loss = 0.20184703\n",
      "Iteration 11, loss = 0.19318960\n",
      "Iteration 12, loss = 0.18455607\n",
      "Iteration 13, loss = 0.17495342\n",
      "Iteration 14, loss = 0.16826375\n",
      "Iteration 15, loss = 0.16274372\n",
      "Iteration 16, loss = 0.15706371\n",
      "Iteration 17, loss = 0.14851015\n",
      "Iteration 18, loss = 0.14530761\n",
      "Iteration 19, loss = 0.14003056\n",
      "Iteration 20, loss = 0.13747148\n",
      "Iteration 21, loss = 0.13236195\n",
      "Iteration 22, loss = 0.12813142\n",
      "Iteration 23, loss = 0.12516182\n",
      "Iteration 24, loss = 0.12130057\n",
      "Iteration 25, loss = 0.11911856\n",
      "Iteration 26, loss = 0.11818320\n",
      "Iteration 27, loss = 0.11209825\n",
      "Iteration 28, loss = 0.11143861\n",
      "Iteration 29, loss = 0.10705172\n",
      "Iteration 30, loss = 0.10368662\n",
      "Iteration 31, loss = 0.10249223\n",
      "Iteration 32, loss = 0.09994383\n",
      "Iteration 33, loss = 0.09753256\n",
      "Iteration 34, loss = 0.09632031\n",
      "Iteration 35, loss = 0.09301653\n",
      "Iteration 36, loss = 0.09095529\n",
      "Iteration 37, loss = 0.08764252\n",
      "Iteration 38, loss = 0.08551761\n",
      "Iteration 39, loss = 0.08569345\n",
      "Iteration 40, loss = 0.08289604\n",
      "Iteration 41, loss = 0.08203379\n",
      "Iteration 42, loss = 0.07882640\n",
      "Iteration 43, loss = 0.07879665\n",
      "Iteration 44, loss = 0.07670743\n",
      "Iteration 45, loss = 0.07566442\n",
      "Iteration 46, loss = 0.07296509\n",
      "Iteration 47, loss = 0.07186052\n",
      "Iteration 48, loss = 0.07062428\n",
      "Iteration 49, loss = 0.06989949\n",
      "Iteration 50, loss = 0.06697303\n",
      "Iteration 51, loss = 0.06556076\n",
      "Iteration 52, loss = 0.06506210\n",
      "Iteration 53, loss = 0.06449078\n",
      "Iteration 54, loss = 0.06346015\n",
      "Iteration 55, loss = 0.06249975\n",
      "Iteration 56, loss = 0.06122331\n",
      "Iteration 57, loss = 0.06045750\n",
      "Iteration 58, loss = 0.05820333\n",
      "Iteration 59, loss = 0.05824451\n",
      "Iteration 60, loss = 0.05601379\n",
      "Iteration 61, loss = 0.05516602\n",
      "Iteration 62, loss = 0.05301766\n",
      "Iteration 63, loss = 0.05334486\n",
      "Iteration 64, loss = 0.05014088\n",
      "Iteration 65, loss = 0.05104577\n",
      "Iteration 66, loss = 0.04998188\n",
      "Iteration 67, loss = 0.04902272\n",
      "Iteration 68, loss = 0.04976465\n",
      "Iteration 69, loss = 0.04549632\n",
      "Iteration 70, loss = 0.04800593\n",
      "Iteration 71, loss = 0.04672734\n",
      "Iteration 72, loss = 0.04455436\n",
      "Iteration 73, loss = 0.04311839\n",
      "Iteration 74, loss = 0.04213141\n",
      "Iteration 75, loss = 0.04215849\n",
      "Iteration 76, loss = 0.04094716\n",
      "Iteration 77, loss = 0.03953847\n",
      "Iteration 78, loss = 0.03944925\n",
      "Iteration 79, loss = 0.03937396\n",
      "Iteration 80, loss = 0.03665632\n",
      "Iteration 81, loss = 0.03847009\n",
      "Iteration 82, loss = 0.03745846\n",
      "Iteration 83, loss = 0.03654796\n",
      "Iteration 84, loss = 0.03568721\n",
      "Iteration 85, loss = 0.03532905\n",
      "Iteration 86, loss = 0.03563957\n",
      "Iteration 87, loss = 0.03473302\n",
      "Iteration 88, loss = 0.03278091\n",
      "Iteration 89, loss = 0.03211196\n",
      "Iteration 90, loss = 0.03032757\n",
      "Iteration 91, loss = 0.02882404\n",
      "Iteration 92, loss = 0.02927331\n",
      "Iteration 93, loss = 0.02822397\n",
      "Iteration 94, loss = 0.02845127\n",
      "Iteration 95, loss = 0.02896329\n",
      "Iteration 96, loss = 0.02700488\n",
      "Iteration 97, loss = 0.02683560\n",
      "Iteration 98, loss = 0.02742338\n",
      "Iteration 99, loss = 0.02608682\n",
      "Iteration 100, loss = 0.02373139\n",
      "Iteration 101, loss = 0.02569323\n",
      "Iteration 102, loss = 0.02414943\n",
      "Iteration 103, loss = 0.02235381\n",
      "Iteration 104, loss = 0.02159319\n",
      "Iteration 105, loss = 0.02224048\n",
      "Iteration 106, loss = 0.02122575\n",
      "Iteration 107, loss = 0.02129988\n",
      "Iteration 108, loss = 0.02171329\n",
      "Iteration 109, loss = 0.02152013\n",
      "Iteration 110, loss = 0.02081731\n",
      "Iteration 111, loss = 0.01933167\n",
      "Iteration 112, loss = 0.01900586\n",
      "Iteration 113, loss = 0.01898392\n",
      "Iteration 114, loss = 0.02223831\n",
      "Iteration 115, loss = 0.02368151\n",
      "Iteration 116, loss = 0.01989476\n",
      "Iteration 117, loss = 0.02018174\n",
      "Iteration 118, loss = 0.01776780\n",
      "Iteration 119, loss = 0.01750051\n",
      "Iteration 120, loss = 0.01835778\n",
      "Iteration 121, loss = 0.01622073\n",
      "Iteration 122, loss = 0.01569958\n",
      "Iteration 123, loss = 0.01736036\n",
      "Iteration 124, loss = 0.01690291\n",
      "Iteration 125, loss = 0.01561393\n",
      "Iteration 126, loss = 0.01361284\n",
      "Iteration 127, loss = 0.01260864\n",
      "Iteration 128, loss = 0.01471602\n",
      "Iteration 129, loss = 0.01496634\n",
      "Iteration 130, loss = 0.01587624\n",
      "Iteration 131, loss = 0.01474795\n",
      "Iteration 132, loss = 0.01210311\n",
      "Iteration 133, loss = 0.01202966\n",
      "Iteration 134, loss = 0.01007772\n",
      "Iteration 135, loss = 0.00971766\n",
      "Iteration 136, loss = 0.00895417\n",
      "Iteration 137, loss = 0.00819586\n",
      "Iteration 138, loss = 0.00816745\n",
      "Iteration 139, loss = 0.01332156\n",
      "Iteration 140, loss = 0.01542900\n",
      "Iteration 141, loss = 0.01384899\n",
      "Iteration 142, loss = 0.01389537\n",
      "Iteration 143, loss = 0.01290231\n",
      "Iteration 144, loss = 0.00922718\n",
      "Iteration 145, loss = 0.00827099\n",
      "Iteration 146, loss = 0.00747544\n",
      "Iteration 147, loss = 0.00650800\n",
      "Iteration 148, loss = 0.00631160\n",
      "Iteration 149, loss = 0.00666095\n",
      "Iteration 150, loss = 0.00568238\n",
      "Iteration 151, loss = 0.00514770\n",
      "Iteration 152, loss = 0.00515908\n",
      "Iteration 153, loss = 0.00491414\n",
      "Iteration 154, loss = 0.00496783\n",
      "Iteration 155, loss = 0.00439601\n",
      "Iteration 156, loss = 0.00440293\n",
      "Iteration 157, loss = 0.00456873\n",
      "Iteration 158, loss = 0.00428272\n",
      "Iteration 159, loss = 0.00439967\n",
      "Iteration 160, loss = 0.00386053\n",
      "Iteration 161, loss = 0.00379364\n",
      "Iteration 162, loss = 0.00369066\n",
      "Iteration 163, loss = 0.00350524\n",
      "Iteration 164, loss = 0.00347792\n",
      "Iteration 165, loss = 0.00367638\n",
      "Iteration 166, loss = 0.00341471\n",
      "Iteration 167, loss = 0.00332883\n",
      "Iteration 168, loss = 0.00323709\n",
      "Iteration 169, loss = 0.00299216\n",
      "Iteration 170, loss = 0.00302119\n",
      "Iteration 171, loss = 0.00292928\n",
      "Iteration 172, loss = 0.00295446\n",
      "Iteration 173, loss = 0.00282722\n",
      "Iteration 174, loss = 0.00271901\n",
      "Iteration 175, loss = 0.00268395\n",
      "Iteration 176, loss = 0.00258494\n",
      "Iteration 177, loss = 0.00251870\n",
      "Iteration 178, loss = 0.00254478\n",
      "Iteration 179, loss = 0.00247306\n",
      "Iteration 180, loss = 0.00252651\n",
      "Iteration 181, loss = 0.00236823\n",
      "Iteration 182, loss = 0.00229379\n",
      "Iteration 183, loss = 0.00226787\n",
      "Iteration 184, loss = 0.00225607\n",
      "Iteration 185, loss = 0.00231582\n",
      "Iteration 186, loss = 0.00217600\n",
      "Iteration 187, loss = 0.00210764\n",
      "Iteration 188, loss = 0.00211095\n",
      "Iteration 189, loss = 0.00206046\n",
      "Iteration 190, loss = 0.00204817\n",
      "Iteration 191, loss = 0.00200730\n",
      "Iteration 192, loss = 0.00195125\n",
      "Iteration 193, loss = 0.00195579\n",
      "Iteration 194, loss = 0.00189666\n",
      "Iteration 195, loss = 0.00191797\n",
      "Iteration 196, loss = 0.00199020\n",
      "Iteration 197, loss = 0.00189055\n",
      "Iteration 198, loss = 0.00184223\n",
      "Iteration 199, loss = 0.00174286\n",
      "Iteration 200, loss = 0.00176015\n",
      "Iteration 201, loss = 0.00173358\n",
      "Iteration 202, loss = 0.00175748\n",
      "Iteration 203, loss = 0.00166732\n",
      "Iteration 204, loss = 0.00163980\n",
      "Iteration 205, loss = 0.00163256\n",
      "Iteration 206, loss = 0.00157427\n",
      "Iteration 207, loss = 0.00156848\n",
      "Iteration 208, loss = 0.00152795\n",
      "Iteration 209, loss = 0.00154257\n",
      "Iteration 210, loss = 0.00149940\n",
      "Iteration 211, loss = 0.00151176\n",
      "Iteration 212, loss = 0.00146531\n",
      "Iteration 213, loss = 0.00148871\n",
      "Iteration 214, loss = 0.00151410\n",
      "Iteration 215, loss = 0.00139973\n",
      "Iteration 216, loss = 0.00137660\n",
      "Iteration 217, loss = 0.00137348\n",
      "Iteration 218, loss = 0.00133561\n",
      "Iteration 219, loss = 0.00133170\n",
      "Iteration 220, loss = 0.00133147\n",
      "Iteration 221, loss = 0.00128930\n",
      "Iteration 222, loss = 0.00129484\n",
      "Iteration 223, loss = 0.00126148\n",
      "Iteration 224, loss = 0.00124662\n",
      "Iteration 225, loss = 0.00123004\n",
      "Iteration 226, loss = 0.00124451\n",
      "Iteration 227, loss = 0.00118201\n",
      "Iteration 228, loss = 0.00121434\n",
      "Iteration 229, loss = 0.00118015\n",
      "Iteration 230, loss = 0.00117113\n",
      "Iteration 231, loss = 0.00114615\n",
      "Iteration 232, loss = 0.00112129\n",
      "Iteration 233, loss = 0.00111960\n",
      "Iteration 234, loss = 0.00110395\n",
      "Iteration 235, loss = 0.00109186\n",
      "Iteration 236, loss = 0.00107132\n",
      "Iteration 237, loss = 0.00106406\n",
      "Iteration 238, loss = 0.00104275\n",
      "Iteration 239, loss = 0.00104830\n",
      "Iteration 240, loss = 0.00104297\n",
      "Iteration 241, loss = 0.00102643\n",
      "Iteration 242, loss = 0.00101123\n",
      "Iteration 243, loss = 0.00099355\n",
      "Iteration 244, loss = 0.00098439\n",
      "Iteration 245, loss = 0.00098720\n",
      "Iteration 246, loss = 0.00097075\n",
      "Iteration 247, loss = 0.00095063\n",
      "Iteration 248, loss = 0.00095116\n",
      "Iteration 249, loss = 0.00093238\n",
      "Iteration 250, loss = 0.00093075\n",
      "Iteration 251, loss = 0.00091930\n",
      "Iteration 252, loss = 0.00090757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.00090408\n",
      "Iteration 254, loss = 0.00088735\n",
      "Iteration 255, loss = 0.00087680\n",
      "Iteration 256, loss = 0.00086868\n",
      "Iteration 257, loss = 0.00086424\n",
      "Iteration 258, loss = 0.00085213\n",
      "Iteration 259, loss = 0.00083985\n",
      "Iteration 260, loss = 0.00083917\n",
      "Iteration 261, loss = 0.00083575\n",
      "Iteration 262, loss = 0.00082074\n",
      "Iteration 263, loss = 0.00080486\n",
      "Iteration 264, loss = 0.00080701\n",
      "Iteration 265, loss = 0.00078951\n",
      "Iteration 266, loss = 0.00080194\n",
      "Iteration 267, loss = 0.00078830\n",
      "Iteration 268, loss = 0.00076745\n",
      "Iteration 269, loss = 0.00076429\n",
      "Iteration 270, loss = 0.00075486\n",
      "Iteration 271, loss = 0.00075534\n",
      "Iteration 272, loss = 0.00074544\n",
      "Iteration 273, loss = 0.00074390\n",
      "Iteration 274, loss = 0.00073105\n",
      "Iteration 275, loss = 0.00072925\n",
      "Iteration 276, loss = 0.00071848\n",
      "Iteration 277, loss = 0.00071350\n",
      "Iteration 278, loss = 0.00070877\n",
      "Iteration 279, loss = 0.00070892\n",
      "Iteration 280, loss = 0.00070246\n",
      "Iteration 281, loss = 0.00069267\n",
      "Iteration 282, loss = 0.00069122\n",
      "Iteration 283, loss = 0.00068454\n",
      "Iteration 284, loss = 0.00067985\n",
      "Iteration 285, loss = 0.00067336\n",
      "Iteration 286, loss = 0.00066202\n",
      "Iteration 287, loss = 0.00065974\n",
      "Iteration 288, loss = 0.00065192\n",
      "Iteration 289, loss = 0.00064927\n",
      "Iteration 290, loss = 0.00064824\n",
      "Iteration 291, loss = 0.00064283\n",
      "Iteration 292, loss = 0.00063829\n",
      "Iteration 293, loss = 0.00062775\n",
      "Iteration 294, loss = 0.00062660\n",
      "Iteration 295, loss = 0.00062199\n",
      "Iteration 296, loss = 0.00061630\n",
      "Iteration 297, loss = 0.00061767\n",
      "Iteration 298, loss = 0.00060723\n",
      "Iteration 299, loss = 0.00060667\n",
      "Iteration 300, loss = 0.00060013\n",
      "Iteration 301, loss = 0.00059294\n",
      "Iteration 302, loss = 0.00058627\n",
      "Iteration 303, loss = 0.00058826\n",
      "Iteration 304, loss = 0.00058213\n",
      "Iteration 305, loss = 0.00057852\n",
      "Iteration 306, loss = 0.00057502\n",
      "Iteration 307, loss = 0.00057350\n",
      "Iteration 308, loss = 0.00056550\n",
      "Iteration 309, loss = 0.00055939\n",
      "Iteration 310, loss = 0.00056068\n",
      "Iteration 311, loss = 0.00055508\n",
      "Iteration 312, loss = 0.00055345\n",
      "Iteration 313, loss = 0.00054837\n",
      "Iteration 314, loss = 0.00054376\n",
      "Iteration 315, loss = 0.00054134\n",
      "Iteration 316, loss = 0.00053475\n",
      "Iteration 317, loss = 0.00053499\n",
      "Iteration 318, loss = 0.00053133\n",
      "Iteration 319, loss = 0.00053065\n",
      "Iteration 320, loss = 0.00052503\n",
      "Iteration 321, loss = 0.00052302\n",
      "Iteration 322, loss = 0.00052003\n",
      "Iteration 323, loss = 0.00051612\n",
      "Iteration 324, loss = 0.00051696\n",
      "Iteration 325, loss = 0.00051189\n",
      "Iteration 326, loss = 0.00050502\n",
      "Iteration 327, loss = 0.00050059\n",
      "Iteration 328, loss = 0.00050215\n",
      "Iteration 329, loss = 0.00050040\n",
      "Iteration 330, loss = 0.00049219\n",
      "Iteration 331, loss = 0.00049223\n",
      "Iteration 332, loss = 0.00048991\n",
      "Iteration 333, loss = 0.00048610\n",
      "Iteration 334, loss = 0.00048294\n",
      "Training loss did not improve more than tol=0.000010 for 40 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=2e-08, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 100, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
       "       n_iter_no_change=40, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=101, shuffle=True, solver='sgd', tol=1e-05,\n",
       "       validation_fraction=0.1, verbose=10, warm_start=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLPC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train=MLPC.predict(X_train)\n",
    "prediccion_real = MLPC.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas de exactitud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "#Training Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La Exactitud del modelo con datos de entrenamiento es :\n",
      "0.999968253968254\n",
      "La Exactitud real del modelo con los datos de prueba es :\n",
      "0.9467619047619048\n"
     ]
    }
   ],
   "source": [
    "# Exactitud de prueba \n",
    "print('La Exactitud del modelo con datos de entrenamiento es :')\n",
    "print(accuracy_score(y_train, prediccion_train))\n",
    "\n",
    "# Exactitud del modelo\n",
    "print('La Exactitud real del modelo con los datos de prueba es :')\n",
    "print(accuracy_score(y_test, prediccion_real))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1005\n",
      "           1       0.98      0.97      0.97      1154\n",
      "           2       0.94      0.95      0.95      1059\n",
      "           3       0.95      0.94      0.94      1082\n",
      "           4       0.94      0.95      0.94      1028\n",
      "           5       0.93      0.92      0.92       952\n",
      "           6       0.96      0.97      0.97      1023\n",
      "           7       0.95      0.95      0.95      1092\n",
      "           8       0.92      0.93      0.92      1010\n",
      "           9       0.94      0.91      0.93      1095\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     10500\n",
      "   macro avg       0.95      0.95      0.95     10500\n",
      "weighted avg       0.95      0.95      0.95     10500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, prediccion_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_submit=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_envio = MLPC.predict(x_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000,)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion_envio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.DataFrame({\"ImageId\": df_test[\"ImageId\"], \n",
    "                       \"Label\" : prediccion_envio})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred.to_csv('final_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
